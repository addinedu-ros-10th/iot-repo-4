#!/usr/bin/env python3
"""
IoT Care Bootstrap Dashboard - Test Runner
ëª¨ë“  í…ŒìŠ¤íŠ¸ë¥¼ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ìˆ˜ì§‘í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸
"""

import unittest
import sys
import os
import json
from datetime import datetime

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.dirname(__file__))

def run_all_tests():
    """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸ§ª IoT Care Bootstrap Dashboard í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ì„¤ì •
    test_dir = os.path.join(os.path.dirname(__file__), 'tests')
    
    # í…ŒìŠ¤íŠ¸ ìŠ¤ìœ„íŠ¸ ìƒì„±
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì¶”ê°€
    unit_test_dir = os.path.join(test_dir, 'unit')
    if os.path.exists(unit_test_dir):
        unit_tests = loader.discover(unit_test_dir, pattern='test_*.py')
        suite.addTests(unit_tests)
        print(f"âœ… ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ë°œê²¬: {unit_test_dir}")
    else:
        print(f"âš ï¸ ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {unit_test_dir}")
    
    # ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ì¶”ê°€
    functional_test_dir = os.path.join(test_dir, 'functional')
    if os.path.exists(functional_test_dir):
        functional_tests = loader.discover(functional_test_dir, pattern='test_*.py')
        suite.addTests(functional_tests)
        print(f"âœ… ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ë°œê²¬: {functional_test_dir}")
    else:
        print(f"âš ï¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {functional_test_dir}")
    
    # í†µí•© í…ŒìŠ¤íŠ¸ ì¶”ê°€
    integration_test_dir = os.path.join(test_dir, 'integration')
    if os.path.exists(integration_test_dir):
        integration_tests = loader.discover(integration_test_dir, pattern='test_*.py')
        suite.addTests(integration_tests)
        print(f"âœ… í†µí•© í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ ë°œê²¬: {integration_test_dir}")
    else:
        print(f"âš ï¸ í†µí•© í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ: {integration_test_dir}")
    
    if suite.countTestCases() == 0:
        print("âŒ ì‹¤í–‰í•  í…ŒìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, 0
    
    print(f"\nğŸ“‹ ì´ {suite.countTestCases()}ê°œì˜ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ë°œê²¬")
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 60)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)
    print(f"ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {result.testsRun}")
    print(f"ì„±ê³µ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"ì‹¤íŒ¨: {len(result.failures)}")
    print(f"ì˜¤ë¥˜: {len(result.errors)}")
    
    # ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ìƒì„¸ ì •ë³´
    if result.failures:
        print(f"\nâŒ ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸ ({len(result.failures)}ê°œ):")
        for test, traceback in result.failures:
            error_msg = traceback.split('AssertionError:')[1].strip() if 'AssertionError:' in traceback else 'Assertion failed'
            print(f"  - {test}: {error_msg}")
    
    # ì˜¤ë¥˜ê°€ ë°œìƒí•œ í…ŒìŠ¤íŠ¸ ìƒì„¸ ì •ë³´
    if result.errors:
        print(f"\nğŸš¨ ì˜¤ë¥˜ê°€ ë°œìƒí•œ í…ŒìŠ¤íŠ¸ ({len(result.errors)}ê°œ):")
        for test, traceback in result.errors:
            error_msg = traceback.split('Exception:')[1].strip() if 'Exception:' in traceback else 'Exception occurred'
            print(f"  - {test}: {error_msg}")
    
    # ì„±ê³µë¥  ê³„ì‚°
    success_rate = ((result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100) if result.testsRun > 0 else 0
    print(f"\nğŸ¯ ì„±ê³µë¥ : {success_rate:.1f}%")
    
    # ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
    save_test_results(result, success_rate)
    
    return result, success_rate

def save_test_results(result, success_rate):
    """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥"""
    test_results = {
        'timestamp': datetime.now().isoformat(),
        'summary': {
            'total_tests': result.testsRun,
            'successful': result.testsRun - len(result.failures) - len(result.errors),
            'failed': len(result.failures),
            'errors': len(result.errors),
            'success_rate': success_rate
        },
        'failures': [
            {
                'test': str(test),
                'traceback': traceback
            } for test, traceback in result.failures
        ],
        'errors': [
            {
                'test': str(test),
                'traceback': traceback
            } for test, traceback in result.errors
        ]
    }
    
    # ê²°ê³¼ íŒŒì¼ ì €ì¥
    results_dir = os.path.join(os.path.dirname(__file__), '..', '..', '..', 'task', 'testing-results')
    os.makedirs(results_dir, exist_ok=True)
    
    results_file = os.path.join(results_dir, f'bootstrap_dashboard_test_results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json')
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(test_results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {results_file}")

def run_specific_test_category(category):
    """íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ í…ŒìŠ¤íŠ¸ë§Œ ì‹¤í–‰"""
    print(f"ğŸ§ª {category} í…ŒìŠ¤íŠ¸ ì‹¤í–‰...")
    print("=" * 60)
    
    test_dir = os.path.join(os.path.dirname(__file__), 'tests', category)
    
    if not os.path.exists(test_dir):
        print(f"âŒ {category} í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_dir}")
        return None, 0
    
    loader = unittest.TestLoader()
    suite = loader.discover(test_dir, pattern='test_*.py')
    
    if suite.countTestCases() == 0:
        print(f"âŒ {category} ì¹´í…Œê³ ë¦¬ì— ì‹¤í–‰í•  í…ŒìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None, 0
    
    print(f"ğŸ“‹ {suite.countTestCases()}ê°œì˜ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ë°œê²¬")
    
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    success_rate = ((result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100) if result.testsRun > 0 else 0
    
    print(f"\nğŸ“Š {category} í…ŒìŠ¤íŠ¸ ê²°ê³¼: {success_rate:.1f}% ì„±ê³µ")
    
    return result, success_rate

if __name__ == '__main__':
    if len(sys.argv) > 1:
        category = sys.argv[1].lower()
        if category in ['unit', 'functional', 'integration']:
            run_specific_test_category(category)
        else:
            print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” í…ŒìŠ¤íŠ¸ ì¹´í…Œê³ ë¦¬: {category}")
            print("ì‚¬ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬: unit, functional, integration")
    else:
        # ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        run_all_tests()
